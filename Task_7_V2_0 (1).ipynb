{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "XVdX3Gq0v3lw"
      },
      "outputs": [],
      "source": [
        "# Importing necessary libraries\n",
        "import os\n",
        "import glob\n",
        "import xml.etree.ElementTree as ET\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import cv2\n",
        "\n",
        "# Path to the input data and annotations\n",
        "input_data_path = 'face-mask-detection/images'\n",
        "annotations_path = \"face-mask-detection/annotations\"\n",
        "images = [*os.listdir(\"face-mask-detection/images\")]\n",
        "output_data_path = '.'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_annotation_object(annotation_object):\n",
        "    params = {}\n",
        "    for param in list(annotation_object):\n",
        "        if param.tag == 'name':\n",
        "            params['name'] = param.text\n",
        "        if param.tag == 'bndbox':\n",
        "            for coord in list(param):\n",
        "                params[coord.tag] = int(coord.text)\n",
        "    return params"
      ],
      "metadata": {
        "id": "QrbUR9lswISE"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = []\n",
        "for anno in glob.glob(annotations_path + \"/*.xml\"):\n",
        "    tree = ET.parse(anno)\n",
        "    root = tree.getroot()\n",
        "    constants = {'file': root.find('filename').text[0:-4]}\n",
        "    objects = root.findall('object')\n",
        "    for obj in objects:\n",
        "        object_params = parse_annotation_object(obj)\n",
        "        dataset.append({**constants, **object_params})\n",
        "\n",
        "df = pd.DataFrame(dataset)"
      ],
      "metadata": {
        "id": "TV-R8icgw5CT"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_test_image = 'maksssksksss0'\n",
        "images.remove(f'{final_test_image}.png')\n",
        "df = df[df[\"file\"] != final_test_image]"
      ],
      "metadata": {
        "id": "-ftWXCVcxA2s"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
        "train_df, val_df = train_test_split(train_df, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "aMwqY-OrxCqn"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for label in df['name'].unique():\n",
        "    for d in ['train', 'test', 'val']:\n",
        "        path = os.path.join(output_data_path, d, label)\n",
        "        os.makedirs(path, exist_ok=True)"
      ],
      "metadata": {
        "id": "62StmD6kxFJ-"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def crop_img(image_path, x_min, y_min, x_max, y_max):\n",
        "    img = Image.open(image_path)\n",
        "    cropped = img.crop((x_min - (x_max - x_min) * 0.1, y_min - (y_max - y_min) * 0.1, x_max + (x_max - x_min) * 0.1, y_max + (y_max - y_min) * 0.1))\n",
        "    return cropped\n",
        "\n",
        "# Saving images to directories\n",
        "def save_image(image, image_name, dataset_type, label):\n",
        "    output_path = os.path.join(output_data_path, dataset_type, label, f'{image_name}.png')\n",
        "    image.save(output_path)\n",
        "\n",
        "for dataset, dataset_type in [(train_df, 'train'), (test_df, 'test'), (val_df, 'val')]:\n",
        "    for _, row in dataset.iterrows():\n",
        "        image_path = os.path.join(input_data_path, row['file'] + '.png')\n",
        "        image = crop_img(image_path, row['xmin'], row['ymin'], row['xmax'], row['ymax'])\n",
        "        save_image(image, row['file'] + '_' + str((row['xmin'], row['ymin'])), dataset_type, row['name'])"
      ],
      "metadata": {
        "id": "_5VWFkrZxIh8"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "    Conv2D(filters=16, kernel_size=3, padding='same', activation='relu', input_shape=(35, 35, 3)),\n",
        "    MaxPooling2D(pool_size=2),\n",
        "    Conv2D(filters=32, kernel_size=3, padding='same', activation='relu'),\n",
        "    MaxPooling2D(pool_size=2),\n",
        "    Conv2D(filters=64, kernel_size=3, padding='same', activation='relu'),\n",
        "    MaxPooling2D(pool_size=2),\n",
        "    Dropout(0.3),\n",
        "    Flatten(),\n",
        "    Dense(units=500, activation='relu'),\n",
        "    Dropout(0.3),\n",
        "    Dense(units=3, activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "UTJRCuYrxKe9"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "OuvthrwQxM_X"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datagen = ImageDataGenerator(\n",
        "    rescale=1.0 / 255, horizontal_flip=True, zoom_range=0.1, shear_range=0.2, width_shift_range=0.1,\n",
        "    height_shift_range=0.1, rotation_range=4, vertical_flip=False\n",
        ")\n",
        "\n",
        "val_datagen = ImageDataGenerator(rescale=1.0 / 255)"
      ],
      "metadata": {
        "id": "x3B4UdjuxOhf"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 8\n",
        "train_generator = datagen.flow_from_directory(directory='train', target_size=(35, 35),\n",
        "                                              class_mode=\"categorical\", batch_size=batch_size, shuffle=True)\n",
        "\n",
        "val_generator = val_datagen.flow_from_directory(directory='val', target_size=(35, 35),\n",
        "                                                class_mode=\"categorical\", batch_size=batch_size, shuffle=True)\n",
        "\n",
        "test_generator = val_datagen.flow_from_directory(directory='test', target_size=(35, 35),\n",
        "                                                 class_mode=\"categorical\", batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4M8rHS7dxQ_E",
        "outputId": "39191ccc-47d7-4dbe-ee2d-21d819df1beb"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 22 images belonging to 3 classes.\n",
            "Found 6 images belonging to 3 classes.\n",
            "Found 7 images belonging to 3 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit_generator(generator=train_generator, epochs=50, validation_data=val_generator, callbacks=[])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jPyJZXKpxSuI",
        "outputId": "9cd4fc8f-11e7-4deb-e037-22d690d8ebee"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-15-60136a4efd23>:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  model.fit_generator(generator=train_generator, epochs=50, validation_data=val_generator, callbacks=[])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 [==============================] - 2s 152ms/step - loss: 0.7656 - accuracy: 0.5909 - val_loss: 2.0289 - val_accuracy: 0.5000\n",
            "Epoch 2/50\n",
            "3/3 [==============================] - 0s 95ms/step - loss: 0.3637 - accuracy: 0.9091 - val_loss: 2.6763 - val_accuracy: 0.5000\n",
            "Epoch 3/50\n",
            "3/3 [==============================] - 0s 90ms/step - loss: 0.4417 - accuracy: 0.9091 - val_loss: 2.5236 - val_accuracy: 0.5000\n",
            "Epoch 4/50\n",
            "3/3 [==============================] - 0s 42ms/step - loss: 0.3827 - accuracy: 0.9091 - val_loss: 1.6586 - val_accuracy: 0.5000\n",
            "Epoch 5/50\n",
            "3/3 [==============================] - 0s 48ms/step - loss: 0.2991 - accuracy: 0.9091 - val_loss: 1.3898 - val_accuracy: 0.5000\n",
            "Epoch 6/50\n",
            "3/3 [==============================] - 0s 39ms/step - loss: 0.2944 - accuracy: 0.9091 - val_loss: 1.4080 - val_accuracy: 0.5000\n",
            "Epoch 7/50\n",
            "3/3 [==============================] - 0s 44ms/step - loss: 0.2679 - accuracy: 0.9091 - val_loss: 1.6079 - val_accuracy: 0.5000\n",
            "Epoch 8/50\n",
            "3/3 [==============================] - 0s 41ms/step - loss: 0.2962 - accuracy: 0.9091 - val_loss: 1.7304 - val_accuracy: 0.5000\n",
            "Epoch 9/50\n",
            "3/3 [==============================] - 0s 38ms/step - loss: 0.2734 - accuracy: 0.9091 - val_loss: 1.7570 - val_accuracy: 0.5000\n",
            "Epoch 10/50\n",
            "3/3 [==============================] - 0s 39ms/step - loss: 0.2641 - accuracy: 0.9091 - val_loss: 1.6265 - val_accuracy: 0.5000\n",
            "Epoch 11/50\n",
            "3/3 [==============================] - 0s 40ms/step - loss: 0.2408 - accuracy: 0.9091 - val_loss: 1.3848 - val_accuracy: 0.5000\n",
            "Epoch 12/50\n",
            "3/3 [==============================] - 0s 41ms/step - loss: 0.2147 - accuracy: 0.9091 - val_loss: 1.3851 - val_accuracy: 0.5000\n",
            "Epoch 13/50\n",
            "3/3 [==============================] - 0s 47ms/step - loss: 0.2137 - accuracy: 0.9091 - val_loss: 1.6952 - val_accuracy: 0.5000\n",
            "Epoch 14/50\n",
            "3/3 [==============================] - 0s 41ms/step - loss: 0.1994 - accuracy: 0.9091 - val_loss: 2.0460 - val_accuracy: 0.5000\n",
            "Epoch 15/50\n",
            "3/3 [==============================] - 0s 40ms/step - loss: 0.1920 - accuracy: 0.9091 - val_loss: 1.7413 - val_accuracy: 0.5000\n",
            "Epoch 16/50\n",
            "3/3 [==============================] - 0s 39ms/step - loss: 0.1518 - accuracy: 0.9091 - val_loss: 1.6756 - val_accuracy: 0.5000\n",
            "Epoch 17/50\n",
            "3/3 [==============================] - 0s 42ms/step - loss: 0.1761 - accuracy: 0.9091 - val_loss: 1.6626 - val_accuracy: 0.5000\n",
            "Epoch 18/50\n",
            "3/3 [==============================] - 0s 43ms/step - loss: 0.1427 - accuracy: 0.9091 - val_loss: 1.9530 - val_accuracy: 0.5000\n",
            "Epoch 19/50\n",
            "3/3 [==============================] - 0s 40ms/step - loss: 0.1297 - accuracy: 0.9091 - val_loss: 2.1592 - val_accuracy: 0.5000\n",
            "Epoch 20/50\n",
            "3/3 [==============================] - 0s 49ms/step - loss: 0.1247 - accuracy: 0.9091 - val_loss: 1.8205 - val_accuracy: 0.5000\n",
            "Epoch 21/50\n",
            "3/3 [==============================] - 0s 40ms/step - loss: 0.1169 - accuracy: 0.9091 - val_loss: 2.0307 - val_accuracy: 0.5000\n",
            "Epoch 22/50\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 0.1095 - accuracy: 0.9091 - val_loss: 2.3034 - val_accuracy: 0.5000\n",
            "Epoch 23/50\n",
            "3/3 [==============================] - 0s 40ms/step - loss: 0.1242 - accuracy: 0.9545 - val_loss: 1.9193 - val_accuracy: 0.5000\n",
            "Epoch 24/50\n",
            "3/3 [==============================] - 0s 42ms/step - loss: 0.1021 - accuracy: 0.9545 - val_loss: 2.2385 - val_accuracy: 0.5000\n",
            "Epoch 25/50\n",
            "3/3 [==============================] - 0s 39ms/step - loss: 0.0883 - accuracy: 0.9545 - val_loss: 2.8224 - val_accuracy: 0.5000\n",
            "Epoch 26/50\n",
            "3/3 [==============================] - 0s 38ms/step - loss: 0.0731 - accuracy: 0.9545 - val_loss: 2.4739 - val_accuracy: 0.5000\n",
            "Epoch 27/50\n",
            "3/3 [==============================] - 0s 44ms/step - loss: 0.1112 - accuracy: 0.9545 - val_loss: 1.9582 - val_accuracy: 0.6667\n",
            "Epoch 28/50\n",
            "3/3 [==============================] - 0s 40ms/step - loss: 0.0528 - accuracy: 1.0000 - val_loss: 2.5513 - val_accuracy: 0.5000\n",
            "Epoch 29/50\n",
            "3/3 [==============================] - 0s 38ms/step - loss: 0.0454 - accuracy: 1.0000 - val_loss: 3.3650 - val_accuracy: 0.5000\n",
            "Epoch 30/50\n",
            "3/3 [==============================] - 0s 38ms/step - loss: 0.0356 - accuracy: 1.0000 - val_loss: 3.8887 - val_accuracy: 0.5000\n",
            "Epoch 31/50\n",
            "3/3 [==============================] - 0s 40ms/step - loss: 0.0117 - accuracy: 1.0000 - val_loss: 4.1345 - val_accuracy: 0.5000\n",
            "Epoch 32/50\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 0.0249 - accuracy: 1.0000 - val_loss: 2.8042 - val_accuracy: 0.8333\n",
            "Epoch 33/50\n",
            "3/3 [==============================] - 0s 83ms/step - loss: 0.0496 - accuracy: 0.9545 - val_loss: 3.3092 - val_accuracy: 0.6667\n",
            "Epoch 34/50\n",
            "3/3 [==============================] - 0s 72ms/step - loss: 0.0365 - accuracy: 1.0000 - val_loss: 4.3661 - val_accuracy: 0.3333\n",
            "Epoch 35/50\n",
            "3/3 [==============================] - 0s 83ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 4.9443 - val_accuracy: 0.3333\n",
            "Epoch 36/50\n",
            "3/3 [==============================] - 0s 65ms/step - loss: 0.0520 - accuracy: 1.0000 - val_loss: 4.7751 - val_accuracy: 0.5000\n",
            "Epoch 37/50\n",
            "3/3 [==============================] - 0s 67ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 3.4255 - val_accuracy: 0.6667\n",
            "Epoch 38/50\n",
            "3/3 [==============================] - 0s 86ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 2.8971 - val_accuracy: 0.8333\n",
            "Epoch 39/50\n",
            "3/3 [==============================] - 0s 64ms/step - loss: 0.1642 - accuracy: 0.9545 - val_loss: 2.4431 - val_accuracy: 0.8333\n",
            "Epoch 40/50\n",
            "3/3 [==============================] - 0s 87ms/step - loss: 0.1410 - accuracy: 0.9091 - val_loss: 4.1900 - val_accuracy: 0.6667\n",
            "Epoch 41/50\n",
            "3/3 [==============================] - 0s 69ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 9.6481 - val_accuracy: 0.5000\n",
            "Epoch 42/50\n",
            "3/3 [==============================] - 0s 44ms/step - loss: 0.3716 - accuracy: 0.9091 - val_loss: 4.2980 - val_accuracy: 0.6667\n",
            "Epoch 43/50\n",
            "3/3 [==============================] - 0s 39ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 1.8952 - val_accuracy: 0.8333\n",
            "Epoch 44/50\n",
            "3/3 [==============================] - 0s 37ms/step - loss: 0.2044 - accuracy: 0.9091 - val_loss: 1.6758 - val_accuracy: 0.8333\n",
            "Epoch 45/50\n",
            "3/3 [==============================] - 0s 42ms/step - loss: 0.0300 - accuracy: 1.0000 - val_loss: 2.8665 - val_accuracy: 0.6667\n",
            "Epoch 46/50\n",
            "3/3 [==============================] - 0s 44ms/step - loss: 0.0526 - accuracy: 0.9545 - val_loss: 3.7911 - val_accuracy: 0.5000\n",
            "Epoch 47/50\n",
            "3/3 [==============================] - 0s 41ms/step - loss: 0.0269 - accuracy: 1.0000 - val_loss: 4.4714 - val_accuracy: 0.5000\n",
            "Epoch 48/50\n",
            "3/3 [==============================] - 0s 47ms/step - loss: 0.0207 - accuracy: 1.0000 - val_loss: 5.1190 - val_accuracy: 0.5000\n",
            "Epoch 49/50\n",
            "3/3 [==============================] - 0s 48ms/step - loss: 0.2045 - accuracy: 0.9091 - val_loss: 4.7972 - val_accuracy: 0.5000\n",
            "Epoch 50/50\n",
            "3/3 [==============================] - 0s 41ms/step - loss: 0.0202 - accuracy: 1.0000 - val_loss: 3.3361 - val_accuracy: 0.5000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7b46405a8fd0>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from keras import layers, models, datasets ,utils\n",
        "from keras.applications import ResNet50, MobileNetV3Small, InceptionV3, VGG16\n",
        "from keras.models import Model\n",
        "\n",
        "\n",
        "\n",
        "# Load ResNet50 model pre-trained on ImageNet data and remove the top layer\n",
        "base_model = VGG16(weights='imagenet', include_top=False)\n",
        "base_model.trainable = False  # Freeze the model\n",
        "\n",
        "# Adding global average pooling to convert features to vectors\n",
        "global_average_layer = layers.GlobalAveragePooling2D()\n",
        "feature_extractor = Model(inputs=base_model.input, outputs=global_average_layer(base_model.output))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kQ-dYpz8xvaX",
        "outputId": "cbbadd3d-dbb4-4401-e96e-1b75b10aeedb"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58889256/58889256 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load ResNet50 model pre-trained on ImageNet data and remove the top layer\n",
        "base_model = VGG16(input_shape=(35, 35, 3), include_top=False)\n",
        "base_model.trainable = False  # Freeze the model\n",
        "\n",
        "model_res = models.Sequential([\n",
        "    base_model,\n",
        "    layers.GlobalAveragePooling2D(),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(128,activation='relu'),\n",
        "    layers.Dense(3, activation='softmax')\n",
        "])\n",
        "model_res.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "0Lz_PojhyNQi"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_res.fit_generator(generator=train_generator, epochs=50, validation_data=val_generator, callbacks=[])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 567
        },
        "id": "QJFKWEhBynXC",
        "outputId": "728d6397-fe23-4afa-e12a-10c5f8491c34"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-29-6898bd01c174>:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  model_res.fit_generator(generator=train_generator, epochs=50, validation_data=val_generator, callbacks=[])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 [==============================] - 2s 477ms/step - loss: 0.8864 - accuracy: 0.6364 - val_loss: 1.4390 - val_accuracy: 0.5000\n",
            "Epoch 2/50\n",
            "3/3 [==============================] - 1s 244ms/step - loss: 0.3639 - accuracy: 0.9091 - val_loss: 1.9340 - val_accuracy: 0.5000\n",
            "Epoch 3/50\n",
            "3/3 [==============================] - 0s 160ms/step - loss: 0.4435 - accuracy: 0.9091 - val_loss: 2.3613 - val_accuracy: 0.5000\n",
            "Epoch 4/50\n",
            "3/3 [==============================] - 0s 176ms/step - loss: 0.4270 - accuracy: 0.9091 - val_loss: 2.5950 - val_accuracy: 0.5000\n",
            "Epoch 5/50\n",
            "3/3 [==============================] - 0s 175ms/step - loss: 0.3365 - accuracy: 0.9091 - val_loss: 2.6985 - val_accuracy: 0.5000\n",
            "Epoch 6/50\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3222 - accuracy: 0.9091"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-6898bd01c174>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_res\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2911\u001b[0m             \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2912\u001b[0m         )\n\u001b[0;32m-> 2913\u001b[0;31m         return self.fit(\n\u001b[0m\u001b[1;32m   2914\u001b[0m             \u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2915\u001b[0m             \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1854\u001b[0m                             \u001b[0mpss_evaluation_shards\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pss_evaluation_shards\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1855\u001b[0m                         )\n\u001b[0;32m-> 1856\u001b[0;31m                     val_logs = self.evaluate(\n\u001b[0m\u001b[1;32m   1857\u001b[0m                         \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1858\u001b[0m                         \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "# Unfreeze the entire model for fine-tuning\n",
        "base_model.trainable = True\n",
        "\n",
        "# It's important to recompile the model after making any changes to the `trainable` attribute of any layer.\n",
        "model_res.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0001),  # Lower learning rate\n",
        "               loss='categorical_crossentropy',\n",
        "               metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "Rd_Kl7mR0NCw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_loss, model_acc = model.evaluate(test_generator)\n",
        "print(f'Test Loss: {model_loss}, Test Accuracy: {model_acc}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XDRxoCcbxpyS",
        "outputId": "d22d78bf-cb50-4d75-df83-6e964205ff5f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 72ms/step - loss: 1.3983 - accuracy: 0.7143\n",
            "Test Loss: 1.3983440399169922, Test Accuracy: 0.7142857313156128\n"
          ]
        }
      ]
    }
  ]
}